- Commit 2 (Prompt Engineering): Design the meta-prompts instructing the "Judge LLM" on how to evaluate responses based on the rubric (e.g., coherence, accuracy, safety).
- Commit 3 (Evaluation Pipeline): Build the asynchronous Python pipeline to concurrently send thousands of candidate model responses to the Azure OpenAI endpoint for scoring.
